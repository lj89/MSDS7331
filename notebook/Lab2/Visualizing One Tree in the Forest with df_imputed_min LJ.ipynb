{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing One Tree in the Forest with df_imputed_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 51 columns):\n",
      "encounter_id                101766 non-null int64\n",
      "patient_nbr                 101766 non-null int64\n",
      "race                        101766 non-null object\n",
      "gender                      101766 non-null object\n",
      "age                         101766 non-null object\n",
      "admission_type_id           101766 non-null int64\n",
      "discharge_disposition_id    101766 non-null int64\n",
      "admission_source_id         101766 non-null int64\n",
      "time_in_hospital            101766 non-null int64\n",
      "medical_specialty           101766 non-null object\n",
      "num_lab_procedures          101766 non-null int64\n",
      "num_procedures              101766 non-null int64\n",
      "num_medications             101766 non-null int64\n",
      "number_outpatient           101766 non-null int64\n",
      "number_emergency            101766 non-null int64\n",
      "number_inpatient            101766 non-null int64\n",
      "number_diagnoses            101766 non-null int64\n",
      "max_glu_serum               101766 non-null object\n",
      "A1Cresult                   101766 non-null object\n",
      "metformin                   101766 non-null object\n",
      "repaglinide                 101766 non-null object\n",
      "nateglinide                 101766 non-null object\n",
      "chlorpropamide              101766 non-null object\n",
      "glimepiride                 101766 non-null object\n",
      "acetohexamide               101766 non-null object\n",
      "glipizide                   101766 non-null object\n",
      "glyburide                   101766 non-null object\n",
      "tolbutamide                 101766 non-null object\n",
      "pioglitazone                101766 non-null object\n",
      "rosiglitazone               101766 non-null object\n",
      "acarbose                    101766 non-null object\n",
      "miglitol                    101766 non-null object\n",
      "troglitazone                101766 non-null object\n",
      "tolazamide                  101766 non-null object\n",
      "insulin                     101766 non-null object\n",
      "glyburide-metformin         101766 non-null object\n",
      "glipizide-metformin         101766 non-null object\n",
      "metformin-rosiglitazone     101766 non-null object\n",
      "metformin-pioglitazone      101766 non-null object\n",
      "change                      101766 non-null object\n",
      "diabetesMed                 101766 non-null object\n",
      "readmitted                  101766 non-null object\n",
      "diag_1_val                  101766 non-null object\n",
      "diag_2_val                  101766 non-null object\n",
      "diag_3_val                  101766 non-null object\n",
      "readmitted_tf               101766 non-null int64\n",
      "medication_count            101766 non-null int64\n",
      "admission_source            95783 non-null object\n",
      "discharge_disposition       98086 non-null object\n",
      "admission_type              97684 non-null object\n",
      "meds_increased              101766 non-null int64\n",
      "dtypes: int64(16), object(35)\n",
      "memory usage: 39.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#import the data\n",
    "directory = 'C:/Users/N1110/Desktop/7331_Project/data/'\n",
    "df = pd.read_csv(directory + 'Diabetes_tmp_Cleaned.csv')\n",
    "df_imputed = df\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 age groups; Ordinal encoding\n",
    "#feature density plot of age can help with answering the question like: does people older age tend to be readmitted?\n",
    "#can use map/apply function to achieve this\n",
    "\n",
    "df_imputed.age[df_imputed.age== '[0-10)'] = 1\n",
    "df_imputed.age[df_imputed.age== '[10-20)'] = 2\n",
    "df_imputed.age[df_imputed.age== '[20-30)'] = 3\n",
    "df_imputed.age[df_imputed.age== '[30-40)'] = 4\n",
    "df_imputed.age[df_imputed.age== '[40-50)'] = 5\n",
    "df_imputed.age[df_imputed.age== '[50-60)'] = 6\n",
    "df_imputed.age[df_imputed.age== '[60-70)'] = 7\n",
    "df_imputed.age[df_imputed.age== '[70-80)'] = 8\n",
    "df_imputed.age[df_imputed.age== '[80-90)'] = 9\n",
    "df_imputed.age[df_imputed.age== '[90-100)'] = 10\n",
    "\n",
    "df_imputed[\"age\"] = df_imputed[\"age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummiesList=[\"discharge_disposition\",\"admission_source\", \"admission_type\"]\n",
    "    \n",
    "df_imputed_min_wDummies = pd.get_dummies(df_imputed[dummiesList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumFeatures= [\"age\",\"num_medications\", \"number_diagnoses\", \"time_in_hospital\",\n",
    "       \"number_emergency\", \"num_lab_procedures\", \"number_inpatient\", \"readmitted_tf\"]\n",
    "\n",
    "df_imputed_min_wDummies= pd.concat((df_imputed_min_wDummies, df_imputed[NumFeatures]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "df_imputed=df_imputed_min_wDummies\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'readmitted_tf' in df_imputed:\n",
    "    y = df_imputed['readmitted_tf'].values # get the labels we want\n",
    "    del df_imputed['readmitted_tf'] # get rid of the class label\n",
    "    X = df_imputed.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N1110\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\N1110\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\N1110\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\N1110\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## Training and Testing Split\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "      # we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "scl_obj.fit(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - roc_auc_score:  0.6601250264605687\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(  random_state = 2000, criterion = 'gini', min_samples_split=10,min_samples_leaf=1,\n",
    "                                max_features='sqrt', max_depth=50, bootstrap = False,\n",
    "                                n_estimators = 1800, verbose = False, n_jobs = 4)\n",
    "rf_clf.fit(X_train_scaled,y_train)\n",
    "\n",
    "preds = rf_clf.predict(X_test_scaled)\n",
    "print('Random Forest - roc_auc_score: ', roc_auc_score(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_forviz=rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to export the tree \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Write the decision tree as a dot file\n",
    "visual_tree =final_model_forviz.estimators_[12]\n",
    "export_graphviz(visual_tree, out_file = 'C:/Users/N1110/Desktop/7331_Project/images/best_tree.dot', feature_names = df_imputed.columns.values, \n",
    "                precision = 2, filled = True, rounded = True, max_depth = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b0f060766906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Import the dot file to a graph and then convert to a png\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/N1110/Desktop/7331_Project/images/best_tree.dot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_jpg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/N1110/Desktop/7331_Project/images/best_tree.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(path, f, prog, encoding)\u001b[0m\n\u001b[0;32m   1732\u001b[0m                 self.write(\n\u001b[0;32m   1733\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1734\u001b[1;33m                     encoding=encoding)\n\u001b[0m\u001b[0;32m   1735\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'write_{fmt}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1815\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "# Use pydot for converting to an image file\n",
    "#pip3 install pydot\n",
    "import pydot\n",
    "\n",
    "# Import the dot file to a graph and then convert to a png\n",
    "(graph, ) = pydot.graph_from_dot_file('C:/Users/N1110/Desktop/7331_Project/images/best_tree.dot')\n",
    "graph.write_jpg('C:/Users/N1110/Desktop/7331_Project/images/best_tree.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
