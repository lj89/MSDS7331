{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing One Tree in the Forest with df_imputed_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 51 columns):\n",
      "encounter_id                101766 non-null int64\n",
      "patient_nbr                 101766 non-null int64\n",
      "race                        101766 non-null object\n",
      "gender                      101766 non-null object\n",
      "age                         101766 non-null object\n",
      "admission_type_id           101766 non-null int64\n",
      "discharge_disposition_id    101766 non-null int64\n",
      "admission_source_id         101766 non-null int64\n",
      "time_in_hospital            101766 non-null int64\n",
      "medical_specialty           101766 non-null object\n",
      "num_lab_procedures          101766 non-null int64\n",
      "num_procedures              101766 non-null int64\n",
      "num_medications             101766 non-null int64\n",
      "number_outpatient           101766 non-null int64\n",
      "number_emergency            101766 non-null int64\n",
      "number_inpatient            101766 non-null int64\n",
      "number_diagnoses            101766 non-null int64\n",
      "max_glu_serum               101766 non-null object\n",
      "A1Cresult                   101766 non-null object\n",
      "metformin                   101766 non-null object\n",
      "repaglinide                 101766 non-null object\n",
      "nateglinide                 101766 non-null object\n",
      "chlorpropamide              101766 non-null object\n",
      "glimepiride                 101766 non-null object\n",
      "acetohexamide               101766 non-null object\n",
      "glipizide                   101766 non-null object\n",
      "glyburide                   101766 non-null object\n",
      "tolbutamide                 101766 non-null object\n",
      "pioglitazone                101766 non-null object\n",
      "rosiglitazone               101766 non-null object\n",
      "acarbose                    101766 non-null object\n",
      "miglitol                    101766 non-null object\n",
      "troglitazone                101766 non-null object\n",
      "tolazamide                  101766 non-null object\n",
      "insulin                     101766 non-null object\n",
      "glyburide-metformin         101766 non-null object\n",
      "glipizide-metformin         101766 non-null object\n",
      "metformin-rosiglitazone     101766 non-null object\n",
      "metformin-pioglitazone      101766 non-null object\n",
      "change                      101766 non-null object\n",
      "diabetesMed                 101766 non-null object\n",
      "readmitted                  101766 non-null object\n",
      "diag_1_val                  101766 non-null object\n",
      "diag_2_val                  101766 non-null object\n",
      "diag_3_val                  101766 non-null object\n",
      "readmitted_tf               101766 non-null int64\n",
      "medication_count            101766 non-null int64\n",
      "admission_source            95783 non-null object\n",
      "discharge_disposition       98086 non-null object\n",
      "admission_type              97684 non-null object\n",
      "meds_increased              101766 non-null int64\n",
      "dtypes: int64(16), object(35)\n",
      "memory usage: 39.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#import the data\n",
    "directory = 'C:/Users/N1110/Desktop/7331_Project/data/'\n",
    "df = pd.read_csv(directory + 'Diabetes_tmp_Cleaned.csv')\n",
    "df_imputed = df\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 age groups; Ordinal encoding\n",
    "#feature density plot of age can help with answering the question like: does people older age tend to be readmitted?\n",
    "#can use map/apply function to achieve this\n",
    "\n",
    "df_imputed.age[df_imputed.age== '[0-10)'] = 1\n",
    "df_imputed.age[df_imputed.age== '[10-20)'] = 2\n",
    "df_imputed.age[df_imputed.age== '[20-30)'] = 3\n",
    "df_imputed.age[df_imputed.age== '[30-40)'] = 4\n",
    "df_imputed.age[df_imputed.age== '[40-50)'] = 5\n",
    "df_imputed.age[df_imputed.age== '[50-60)'] = 6\n",
    "df_imputed.age[df_imputed.age== '[60-70)'] = 7\n",
    "df_imputed.age[df_imputed.age== '[70-80)'] = 8\n",
    "df_imputed.age[df_imputed.age== '[80-90)'] = 9\n",
    "df_imputed.age[df_imputed.age== '[90-100)'] = 10\n",
    "\n",
    "df_imputed[\"age\"] = df_imputed[\"age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummiesList=[\"discharge_disposition\",\"admission_source\", \"admission_type\"]\n",
    "    \n",
    "df_imputed_min_wDummies = pd.get_dummies(df_imputed[dummiesList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumFeatures= [\"age\",\"num_medications\", \"number_diagnoses\", \"time_in_hospital\",\n",
    "       \"number_emergency\", \"num_lab_procedures\", \"number_inpatient\", \"medication_count\", \"readmitted_tf\"]\n",
    "\n",
    "df_imputed_min_wDummies= pd.concat((df_imputed_min_wDummies, df_imputed[NumFeatures]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 54 columns):\n",
      "discharge_disposition_Admitted as an inpatient to this hospital                                                                    101766 non-null uint8\n",
      "discharge_disposition_Discharged to home                                                                                           101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to ICF                                                                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to SNF                                                                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to a federal health care facility.                                                    101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to a long term care hospital.                                                         101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.      101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to another rehab fac including rehab units of a hospital.                             101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to another short term hospital                                                        101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to another type of inpatient care institution                                         101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to home under care of Home IV provider                                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to home with home health service                                                      101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred within this institution to Medicare approved swing bed                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred/referred another institution for outpatient services                                  101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital    101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred/referred to this institution for outpatient services                                  101766 non-null uint8\n",
      "discharge_disposition_Expired                                                                                                      101766 non-null uint8\n",
      "discharge_disposition_Expired at home. Medicaid only, hospice.                                                                     101766 non-null uint8\n",
      "discharge_disposition_Expired in a medical facility. Medicaid only, hospice.                                                       101766 non-null uint8\n",
      "discharge_disposition_Hospice / home                                                                                               101766 non-null uint8\n",
      "discharge_disposition_Hospice / medical facility                                                                                   101766 non-null uint8\n",
      "discharge_disposition_Left AMA                                                                                                     101766 non-null uint8\n",
      "discharge_disposition_Neonate discharged to another hospital for neonatal aftercare                                                101766 non-null uint8\n",
      "discharge_disposition_Not Mapped                                                                                                   101766 non-null uint8\n",
      "discharge_disposition_Still patient or expected to return for outpatient services                                                  101766 non-null uint8\n",
      "admission_source_Clinic Referral                                                                                                   101766 non-null uint8\n",
      "admission_source_Court/Law Enforcement                                                                                             101766 non-null uint8\n",
      "admission_source_Emergency Room                                                                                                    101766 non-null uint8\n",
      "admission_source_Extramural Birth                                                                                                  101766 non-null uint8\n",
      "admission_source_HMO Referral                                                                                                      101766 non-null uint8\n",
      "admission_source_Not Available                                                                                                     101766 non-null uint8\n",
      "admission_source_Not Mapped                                                                                                        101766 non-null uint8\n",
      "admission_source_Physician Referral                                                                                                101766 non-null uint8\n",
      "admission_source_Transfer from Ambulatory Surgery Center                                                                           101766 non-null uint8\n",
      "admission_source_Transfer from a Skilled Nursing Facility (SNF)                                                                    101766 non-null uint8\n",
      "admission_source_Transfer from a hospital                                                                                          101766 non-null uint8\n",
      "admission_source_Transfer from another health care facility                                                                        101766 non-null uint8\n",
      "admission_source_Transfer from critical access hospital                                                                            101766 non-null uint8\n",
      "admission_source_Transfer from hospital inpt/same fac reslt in a sep claim                                                         101766 non-null uint8\n",
      "admission_type_Elective                                                                                                            101766 non-null uint8\n",
      "admission_type_Emergency                                                                                                           101766 non-null uint8\n",
      "admission_type_Newborn                                                                                                             101766 non-null uint8\n",
      "admission_type_Not Available                                                                                                       101766 non-null uint8\n",
      "admission_type_Not Mapped                                                                                                          101766 non-null uint8\n",
      "admission_type_Trauma Center                                                                                                       101766 non-null uint8\n",
      "admission_type_Urgent                                                                                                              101766 non-null uint8\n",
      "age                                                                                                                                101766 non-null int32\n",
      "num_medications                                                                                                                    101766 non-null int64\n",
      "number_diagnoses                                                                                                                   101766 non-null int64\n",
      "time_in_hospital                                                                                                                   101766 non-null int64\n",
      "number_emergency                                                                                                                   101766 non-null int64\n",
      "num_lab_procedures                                                                                                                 101766 non-null int64\n",
      "number_inpatient                                                                                                                   101766 non-null int64\n",
      "medication_count                                                                                                                   101766 non-null int64\n",
      "dtypes: int32(1), int64(7), uint8(46)\n",
      "memory usage: 10.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_imputed_min_wDummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "df_imputed=df_imputed_min_wDummies\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'readmitted_tf' in df_imputed:\n",
    "    y = df_imputed['readmitted_tf'].values # get the labels we want\n",
    "    del df_imputed['readmitted_tf'] # get rid of the class label\n",
    "    X = df_imputed.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and Testing Split\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "      # we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "scl_obj.fit(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - roc_auc_score:  0.6641114682074046\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(  random_state = 2000, criterion = 'gini', min_samples_split=10,min_samples_leaf=1,\n",
    "                                max_features='sqrt', max_depth=50, bootstrap = False,\n",
    "                                n_estimators = 1800, verbose = False, n_jobs = 4)\n",
    "rf_clf.fit(X_train_scaled,y_train)\n",
    "\n",
    "preds = rf_clf.predict(X_test_scaled)\n",
    "print('Random Forest - roc_auc_score: ', roc_auc_score(y_test, preds)) \n",
    "\n",
    "#model without 'medication_count' variable:  Random Forest - roc_auc_score:  0.6601250264605687\n",
    "#model with 'medication_count' variable:  Random Forest - roc_auc_score:  0.6641114682074046\n",
    "#slight increase\n",
    "# ！！！！！！！！！！！！！！model with all variables still got higher auc for RF 0.679376684881603 ！！！！！！！！！！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to create viz of one tree\n",
    "final_model_forviz=rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to export the tree \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Write the decision tree as a dot file\n",
    "visual_tree =final_model_forviz.estimators_[12]\n",
    "export_graphviz(visual_tree, out_file = 'C:/Users/N1110/Desktop/7331_Project/images/best_tree.dot', feature_names = df_imputed.columns.values, \n",
    "                precision = 2, filled = True, rounded = True, max_depth = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-b0f060766906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Import the dot file to a graph and then convert to a png\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/N1110/Desktop/7331_Project/images/best_tree.dot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_jpg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/N1110/Desktop/7331_Project/images/best_tree.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(path, f, prog, encoding)\u001b[0m\n\u001b[0;32m   1732\u001b[0m                 self.write(\n\u001b[0;32m   1733\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1734\u001b[1;33m                     encoding=encoding)\n\u001b[0m\u001b[0;32m   1735\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'write_{fmt}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1815\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "# Use pydot for converting to an image file\n",
    "#pip3 install pydot\n",
    "import pydot\n",
    "\n",
    "# Import the dot file to a graph and then convert to a png\n",
    "(graph, ) = pydot.graph_from_dot_file('C:/Users/N1110/Desktop/7331_Project/images/best_tree.dot')\n",
    "graph.write_jpg('C:/Users/N1110/Desktop/7331_Project/images/best_tree.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost df_imputed_min dataset model vs. baseline model with all variables model\n",
    "\n",
    "### XGBoost baseline  model for df_imputed_min dataset\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "#XGBOOST parameters 1\n",
    "MAX_ROUNDS = 1000\n",
    "EARLY_STOP = 50\n",
    "OPT_ROUNDS = 1000\n",
    "VERBOSE_EVAL = 50\n",
    "RANDOM_STATE = 2000\n",
    "\n",
    "#XGBOOST transform data into DMatrix format for modeling\n",
    "dtrain = xgb.DMatrix(X_train_scaled, y_train)\n",
    "dvalid = xgb.DMatrix(X_test_scaled, y_test)\n",
    "type(dtrain)\n",
    "\n",
    "\n",
    "# XGBoost Parameters 2\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "#params['objective'] = 'multi:softmax'\n",
    "#params['objective'] = 'reg:linear'\n",
    "params['eta'] = 0.039\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 2\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.9\n",
    "params['eval_metric'] = 'auc'\n",
    "params['random_state'] = RANDOM_STATE\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.630167\tvalid-auc:0.626652\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.712641\tvalid-auc:0.711675\n",
      "[100]\ttrain-auc:0.719279\tvalid-auc:0.71933\n",
      "[150]\ttrain-auc:0.725965\tvalid-auc:0.727298\n",
      "[200]\ttrain-auc:0.729865\tvalid-auc:0.731484\n",
      "[250]\ttrain-auc:0.732551\tvalid-auc:0.734486\n",
      "[300]\ttrain-auc:0.734347\tvalid-auc:0.736519\n",
      "[350]\ttrain-auc:0.735593\tvalid-auc:0.737706\n",
      "[400]\ttrain-auc:0.736622\tvalid-auc:0.738797\n",
      "[450]\ttrain-auc:0.737973\tvalid-auc:0.739935\n",
      "[500]\ttrain-auc:0.738855\tvalid-auc:0.7408\n",
      "[550]\ttrain-auc:0.739727\tvalid-auc:0.741469\n",
      "[600]\ttrain-auc:0.740305\tvalid-auc:0.742042\n",
      "[650]\ttrain-auc:0.740912\tvalid-auc:0.742415\n",
      "[700]\ttrain-auc:0.741497\tvalid-auc:0.742847\n",
      "[750]\ttrain-auc:0.742118\tvalid-auc:0.743257\n",
      "[800]\ttrain-auc:0.742659\tvalid-auc:0.743525\n",
      "[850]\ttrain-auc:0.743049\tvalid-auc:0.743724\n",
      "[900]\ttrain-auc:0.743634\tvalid-auc:0.743976\n",
      "[950]\ttrain-auc:0.744101\tvalid-auc:0.744181\n",
      "[999]\ttrain-auc:0.744676\tvalid-auc:0.744422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_clf = xgb.train(params,\n",
    "                   dtrain,\n",
    "                   MAX_ROUNDS,\n",
    "                   watchlist,\n",
    "                   early_stopping_rounds = EARLY_STOP,\n",
    "                   maximize = True,\n",
    "                   verbose_eval = VERBOSE_EVAL)\n",
    "\n",
    "\n",
    "#all variables model\n",
    "#Wall time: 3min 48s\n",
    "#[999]\ttrain-auc:0.756217\tvalid-auc:0.748447\n",
    "\n",
    "#df_imputed_min dataset model (12 varibales) without 'medication_count'\n",
    "#train within one min, similar auc\n",
    "#[999]\ttrain-auc:0.74347\tvalid-auc:0.743672\n",
    "\n",
    "\n",
    "#df_imputed_min dataset model with 'medication_count'\n",
    "# train for one min\n",
    "#[999]\ttrain-auc:0.744676\tvalid-auc:0.744422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "#at least include the parameters already included in the baseline model for chance to find one better than base model.\n",
    "params = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 2],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.9],\n",
    "        'max_depth': [2, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed:  1.7min remaining:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed:  1.8min remaining:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed:  2.0min remaining:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed:  2.6min remaining:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed:  2.6min remaining:   45.3s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:  2.8min finished\n",
      "\n",
      " Time taken: 0 hours 4 minutes and 18.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Thanks for Zack's suggestion\n",
    "# under the condition of same list of parameters to be tuned:\n",
    "# all variables model runtime 24-30 mins\n",
    "# df_imputed_min dataset model 4 mins\n",
    "## grid search in a parallized fashion\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "folds = 3\n",
    "param_comb = 3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train_scaled,y_train), verbose=50, random_state=2000)\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
      "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=0.6)\n",
      "\n",
      " Best normalized gini score for 3-fold search with 3 parameter combinations:\n",
      "0.4868555900780789\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Best hyperparameters\n",
    "\n",
    "Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
    "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.6)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 3 parameter combinations:\n",
    "0.4868555900780789\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 1 minutes and 22.29 seconds.\n"
     ]
    }
   ],
   "source": [
    "#traing time comparsion\n",
    "#df_imputed_min dataset model vs. baseline model with all variables model\n",
    "#run for \n",
    "#evaulate the performance of the model best parameters\n",
    "# timer the training time\n",
    "start_time = timer(None)\n",
    "\n",
    "xgb_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
    "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.6)\n",
    "\n",
    "xgb_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "timer(start_time)\n",
    "\n",
    "#training time\n",
    "#all variables model Time taken: 0 hours 8 minutes and 24.05 seconds.\n",
    "#df_imputed_min dataset model Time taken: 0 hours 1 minutes and 22.29 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 0 minutes and 0.63 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N1110\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# timer the testing time\n",
    "start_time = timer(None)\n",
    "preds = xgb_best.predict(X_test_scaled)\n",
    "timer(start_time)\n",
    "\n",
    "#testing time\n",
    "# all variables model  Time taken: 0 hours 0 minutes and 0.91 seconds.\n",
    "#df_imputed_min dataset model   Time taken: 0 hours 0 minutes and 0.63 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB - roc_auc_score:  0.6696882681547426\n"
     ]
    }
   ],
   "source": [
    "print('XGB - roc_auc_score: ', roc_auc_score(y_test, preds)) \n",
    "#all variables model  XGB - roc_auc_score:  0.677932172132421\n",
    "#df_imputed_min dataset model  XGB - roc_auc_score:  0.6696882681547426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -9.95%.\n"
     ]
    }
   ],
   "source": [
    "#improvement after parameter tuning\n",
    "\n",
    "# The reason I want to keep both baseline model and refined model is to show the effect of Hyperparameter Tuning. \n",
    "# To see increase the AUC by what percentage.\n",
    "\n",
    "XGBrandom_accuracy = 0.6696882681547426\n",
    "XGBbase_accuracy =0.743672\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (XGBrandom_accuracy - XGBbase_accuracy) / XGBbase_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### since the runtime reduced sigificantly for df_imputed_min dataset model (1/8), able to try larger set of parameters\n",
    "\n",
    "#### used\n",
    "params = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 2],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.9],\n",
    "        'max_depth': [2, 5]\n",
    "        }\n",
    "\n",
    "param_comb = 3\n",
    "\n",
    "32 combinations\n",
    "\n",
    "#### Now want to try A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [2, 3, 4, 5]\n",
    "        }\n",
    "        \n",
    "param_comb = 5\n",
    "\n",
    "3*4*3*4*4= 576 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*4*3*4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [2, 3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:  5.6min remaining:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:  5.7min remaining:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:  5.7min remaining:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:  6.1min remaining:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:  6.8min remaining:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:  7.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:  7.0min finished\n",
      "\n",
      " Time taken: 0 hours 8 minutes and 18.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Grid search in a parallized fashion\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train_scaled,y_train), verbose=50, random_state=2000)\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#for df_imputed_min dataset model without 'medication_count' Time taken: 0 hours 8 minutes and 0.77 seconds.\n",
    "# for df_imputed_min dataset model without 'medication_count'   Time taken: 0 hours 8 minutes and 18.21 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
      "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
      "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1.0)\n",
      "\n",
      " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
      "0.48660500355915715\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from narrow list\n",
    "#### Results - Best hyperparameters for all variables model\n",
    "\n",
    "Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
    "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.6)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 3 parameter combinations:\n",
    "0.4868555900780789\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}\n",
    "\n",
    "#### Results from larger list for df_imputed_min dataset model without 'medication_count'\n",
    " Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
    "0.48276429835940937\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}\n",
    "\n",
    "\n",
    "#### Results from larger list for df_imputed_min dataset model without 'medication_count'\n",
    "#### same results of parameters as df_imputed_min dataset model without 'medication_count'\n",
    " Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
    "0.48660500355915715\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 1 minutes and 27.16 seconds.\n"
     ]
    }
   ],
   "source": [
    "#evaulate the performance of the model best parameters\n",
    "# timer the training time\n",
    "start_time = timer(None)\n",
    "\n",
    "xgb_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    "xgb_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 0 minutes and 0.57 seconds.\n"
     ]
    }
   ],
   "source": [
    "# timer the testing time\n",
    "start_time = timer(None)\n",
    "preds = xgb_best.predict(X_test_scaled)\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB - roc_auc_score:  0.6688937079820751\n"
     ]
    }
   ],
   "source": [
    "print('XGB - roc_auc_score: ', roc_auc_score(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -10.06%.\n"
     ]
    }
   ],
   "source": [
    "#improvement after parameter tuning\n",
    "\n",
    "XGBrandom_accuracy = 0.6688937079820751\n",
    "# 0.6688937079820751 for df_imputed_min dataset model with 'medication_count' \n",
    "# 0.6691181476110993  for df_imputed_min dataset model without 'medication_count' \n",
    "# 0.6696882681547426 for all variables model\n",
    "\n",
    "\n",
    "# show the impact of FE (feature engineering)\n",
    "# 'medication_count' varibale does help with increase the auc \n",
    "\n",
    "#also, insulin seem to be a important varibale according to important plot in another notebook. \n",
    "# it makes so much sense and align with our domain knowledge.\n",
    "\n",
    "XGBbase_accuracy =0.743672\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (XGBrandom_accuracy - XGBbase_accuracy) / XGBbase_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for 10 mins\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "#%%time\n",
    "#try run with all medications\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM AUC: 0.6672284951485267\n"
     ]
    }
   ],
   "source": [
    "#get SVM AUC\n",
    "roc = roc_auc_score(y_test,y_hat)\n",
    "print('SVM AUC:', roc )\n",
    "\n",
    "#SVM AUC for all variables model:  SVM AUC: 0.6658213006434637\n",
    "#SVM AUC for df_imputed_min model: SVM AUC: 0.6672284951485267  higherthan all variables model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
