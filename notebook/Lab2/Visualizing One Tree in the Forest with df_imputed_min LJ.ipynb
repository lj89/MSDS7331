{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing One Tree in the Forest with df_imputed_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 51 columns):\n",
      "encounter_id                101766 non-null int64\n",
      "patient_nbr                 101766 non-null int64\n",
      "race                        101766 non-null object\n",
      "gender                      101766 non-null object\n",
      "age                         101766 non-null object\n",
      "admission_type_id           101766 non-null int64\n",
      "discharge_disposition_id    101766 non-null int64\n",
      "admission_source_id         101766 non-null int64\n",
      "time_in_hospital            101766 non-null int64\n",
      "medical_specialty           101766 non-null object\n",
      "num_lab_procedures          101766 non-null int64\n",
      "num_procedures              101766 non-null int64\n",
      "num_medications             101766 non-null int64\n",
      "number_outpatient           101766 non-null int64\n",
      "number_emergency            101766 non-null int64\n",
      "number_inpatient            101766 non-null int64\n",
      "number_diagnoses            101766 non-null int64\n",
      "max_glu_serum               101766 non-null object\n",
      "A1Cresult                   101766 non-null object\n",
      "metformin                   101766 non-null object\n",
      "repaglinide                 101766 non-null object\n",
      "nateglinide                 101766 non-null object\n",
      "chlorpropamide              101766 non-null object\n",
      "glimepiride                 101766 non-null object\n",
      "acetohexamide               101766 non-null object\n",
      "glipizide                   101766 non-null object\n",
      "glyburide                   101766 non-null object\n",
      "tolbutamide                 101766 non-null object\n",
      "pioglitazone                101766 non-null object\n",
      "rosiglitazone               101766 non-null object\n",
      "acarbose                    101766 non-null object\n",
      "miglitol                    101766 non-null object\n",
      "troglitazone                101766 non-null object\n",
      "tolazamide                  101766 non-null object\n",
      "insulin                     101766 non-null object\n",
      "glyburide-metformin         101766 non-null object\n",
      "glipizide-metformin         101766 non-null object\n",
      "metformin-rosiglitazone     101766 non-null object\n",
      "metformin-pioglitazone      101766 non-null object\n",
      "change                      101766 non-null object\n",
      "diabetesMed                 101766 non-null object\n",
      "readmitted                  101766 non-null object\n",
      "diag_1_val                  101766 non-null object\n",
      "diag_2_val                  101766 non-null object\n",
      "diag_3_val                  101766 non-null object\n",
      "readmitted_tf               101766 non-null int64\n",
      "medication_count            101766 non-null int64\n",
      "admission_source            95783 non-null object\n",
      "discharge_disposition       98086 non-null object\n",
      "admission_type              97684 non-null object\n",
      "meds_increased              101766 non-null int64\n",
      "dtypes: int64(16), object(35)\n",
      "memory usage: 39.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#import the data\n",
    "directory = 'C:/githubrepo/7331_Project/data/'\n",
    "df = pd.read_csv(directory + 'Diabetic_Cleaned.csv')\n",
    "df_imputed = df\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 age groups; Ordinal encoding\n",
    "#feature density plot of age can help with answering the question like: does people older age tend to be readmitted?\n",
    "#can use map/apply function to achieve this\n",
    "\n",
    "df_imputed.age[df_imputed.age== '[0-10)'] = 1\n",
    "df_imputed.age[df_imputed.age== '[10-20)'] = 2\n",
    "df_imputed.age[df_imputed.age== '[20-30)'] = 3\n",
    "df_imputed.age[df_imputed.age== '[30-40)'] = 4\n",
    "df_imputed.age[df_imputed.age== '[40-50)'] = 5\n",
    "df_imputed.age[df_imputed.age== '[50-60)'] = 6\n",
    "df_imputed.age[df_imputed.age== '[60-70)'] = 7\n",
    "df_imputed.age[df_imputed.age== '[70-80)'] = 8\n",
    "df_imputed.age[df_imputed.age== '[80-90)'] = 9\n",
    "df_imputed.age[df_imputed.age== '[90-100)'] = 10\n",
    "\n",
    "df_imputed[\"age\"] = df_imputed[\"age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummiesList=[\"discharge_disposition\",\"admission_source\", \"admission_type\"]\n",
    "    \n",
    "df_imputed_min_wDummies = pd.get_dummies(df_imputed[dummiesList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumFeatures= [\"age\",\"num_medications\", \"number_diagnoses\", \"time_in_hospital\",\n",
    "       \"number_emergency\", \"num_lab_procedures\", \"number_inpatient\", \"medication_count\", \"readmitted_tf\"]\n",
    "\n",
    "df_imputed_min_wDummies= pd.concat((df_imputed_min_wDummies, df_imputed[NumFeatures]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 55 columns):\n",
      "discharge_disposition_Admitted as an inpatient to this hospital                                                                    101766 non-null uint8\n",
      "discharge_disposition_Discharged to home                                                                                           101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to ICF                                                                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to SNF                                                                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to a federal health care facility.                                                    101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to a long term care hospital.                                                         101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.      101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to another rehab fac including rehab units of a hospital.                             101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to another short term hospital                                                        101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to another type of inpatient care institution                                         101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to home under care of Home IV provider                                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred to home with home health service                                                      101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred within this institution to Medicare approved swing bed                                101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred/referred another institution for outpatient services                                  101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital    101766 non-null uint8\n",
      "discharge_disposition_Discharged/transferred/referred to this institution for outpatient services                                  101766 non-null uint8\n",
      "discharge_disposition_Expired                                                                                                      101766 non-null uint8\n",
      "discharge_disposition_Expired at home. Medicaid only, hospice.                                                                     101766 non-null uint8\n",
      "discharge_disposition_Expired in a medical facility. Medicaid only, hospice.                                                       101766 non-null uint8\n",
      "discharge_disposition_Hospice / home                                                                                               101766 non-null uint8\n",
      "discharge_disposition_Hospice / medical facility                                                                                   101766 non-null uint8\n",
      "discharge_disposition_Left AMA                                                                                                     101766 non-null uint8\n",
      "discharge_disposition_Neonate discharged to another hospital for neonatal aftercare                                                101766 non-null uint8\n",
      "discharge_disposition_Not Mapped                                                                                                   101766 non-null uint8\n",
      "discharge_disposition_Still patient or expected to return for outpatient services                                                  101766 non-null uint8\n",
      "admission_source_Clinic Referral                                                                                                   101766 non-null uint8\n",
      "admission_source_Court/Law Enforcement                                                                                             101766 non-null uint8\n",
      "admission_source_Emergency Room                                                                                                    101766 non-null uint8\n",
      "admission_source_Extramural Birth                                                                                                  101766 non-null uint8\n",
      "admission_source_HMO Referral                                                                                                      101766 non-null uint8\n",
      "admission_source_Not Available                                                                                                     101766 non-null uint8\n",
      "admission_source_Not Mapped                                                                                                        101766 non-null uint8\n",
      "admission_source_Physician Referral                                                                                                101766 non-null uint8\n",
      "admission_source_Transfer from Ambulatory Surgery Center                                                                           101766 non-null uint8\n",
      "admission_source_Transfer from a Skilled Nursing Facility (SNF)                                                                    101766 non-null uint8\n",
      "admission_source_Transfer from a hospital                                                                                          101766 non-null uint8\n",
      "admission_source_Transfer from another health care facility                                                                        101766 non-null uint8\n",
      "admission_source_Transfer from critical access hospital                                                                            101766 non-null uint8\n",
      "admission_source_Transfer from hospital inpt/same fac reslt in a sep claim                                                         101766 non-null uint8\n",
      "admission_type_Elective                                                                                                            101766 non-null uint8\n",
      "admission_type_Emergency                                                                                                           101766 non-null uint8\n",
      "admission_type_Newborn                                                                                                             101766 non-null uint8\n",
      "admission_type_Not Available                                                                                                       101766 non-null uint8\n",
      "admission_type_Not Mapped                                                                                                          101766 non-null uint8\n",
      "admission_type_Trauma Center                                                                                                       101766 non-null uint8\n",
      "admission_type_Urgent                                                                                                              101766 non-null uint8\n",
      "age                                                                                                                                101766 non-null int32\n",
      "num_medications                                                                                                                    101766 non-null int64\n",
      "number_diagnoses                                                                                                                   101766 non-null int64\n",
      "time_in_hospital                                                                                                                   101766 non-null int64\n",
      "number_emergency                                                                                                                   101766 non-null int64\n",
      "num_lab_procedures                                                                                                                 101766 non-null int64\n",
      "number_inpatient                                                                                                                   101766 non-null int64\n",
      "medication_count                                                                                                                   101766 non-null int64\n",
      "readmitted_tf                                                                                                                      101766 non-null int64\n",
      "dtypes: int32(1), int64(8), uint8(46)\n",
      "memory usage: 11.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_imputed_min_wDummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "df_imputed=df_imputed_min_wDummies\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'readmitted_tf' in df_imputed:\n",
    "    y = df_imputed['readmitted_tf'].values # get the labels we want\n",
    "    del df_imputed['readmitted_tf'] # get rid of the class label\n",
    "    X = df_imputed.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\DS7331_35r\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\DS7331_35r\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\DS7331_35r\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\DS7331_35r\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## Training and Testing Split\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "      # we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "scl_obj.fit(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - roc_auc_score:  0.6644985945227716\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(  random_state = 2000, criterion = 'gini', min_samples_split=10,min_samples_leaf=1,\n",
    "                                max_features='sqrt', max_depth=50, bootstrap = False,\n",
    "                                n_estimators = 1800, verbose = False, n_jobs = 4)\n",
    "rf_clf.fit(X_train_scaled,y_train)\n",
    "\n",
    "preds = rf_clf.predict(X_test_scaled)\n",
    "print('Random Forest - roc_auc_score: ', roc_auc_score(y_test, preds)) \n",
    "\n",
    "#model without 'medication_count' variable:  Random Forest - roc_auc_score:  0.6601250264605687\n",
    "#model with 'medication_count' variable:  Random Forest - roc_auc_score:  0.6641114682074046\n",
    "#slight increase\n",
    "# ！！！！！！！！！！！！！！model with all variables still got higher auc for RF 0.679376684881603 ！！！！！！！！！！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "#probs is the result of a model.predict_proba(x_test) call\n",
    "\n",
    "#This function plots an ROC curve\n",
    "def rocCurvePlot(probs, y_test1):\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test1, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "# A function to find the optimal cutoff point from ROC curve\n",
    "\n",
    "#https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\"Parameters:\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "    ----------\n",
    "    Return: list type, with optimal cutoff value\n",
    "    \"\"\"\n",
    "    predicted = predicted[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.ix[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmczfX+wPHXm0JFG1okUbQgSRNaaFE3IRSJpFTS7pIWdW+3/Vba+6VFSFehJEvdSrdspWTJkiWylCWEkG0s4/374/2d5phmzpwZc+Z7zpn38/GYh/P9nu+c8z7fOc77fD/L+yOqinPOOZebEmEH4JxzLrF5onDOOReVJwrnnHNReaJwzjkXlScK55xzUXmicM45F5UnChczEekoIp+HHUciEZEtInJ8CM9bVURURPYr6ueOBxGZKyLnF+D3/D1ZBDxRJCkR+VlEtgcfVKtFZKCIlI3nc6rqu6r6t3g+RyQROVtExorIZhHZJCIfiUjNonr+HOIZLyJdIvepallVXRKn5ztRRIaJyLrg9c8WkbtEpGQ8nq+ggoRVfV8eQ1Vrqer4PJ7nL8mxqN+TxZUniuR2maqWBeoCpwP3hxxPgeT0rVhEzgI+B0YBlYBqwCxgUjy+wSfaN3MROQH4DlgOnKqqhwBXAmlAuUJ+rtBee6Kdd5cLVfWfJPwBfgYuitjuDfw3Yrs08CywDFgDvA4cEHF/K2Am8AewGGga7D8E6A+sAlYCjwMlg/s6A18Ht18Hns0W0yjgruB2JWA4sBZYCnSLOO5h4APgneD5u+Tw+r4CXs1h/6fAf4Lb5wMrgAeAdcE56RjLOYj43fuA1cAg4DDg4yDmDcHtysHxTwAZQDqwBXgl2K9A9eD2QKAP8F9gM/ZBf0JEPH8DFgCbgFeBCTm99uDYdyL/njncXzV47uuC17cO+EfE/fWBb4GNwd/yFaBUxP0K3A78BCwN9r2EJaY/gOlAo4jjSwbneXHw2qYDxwITg8faGpyXq4LjW2Dvr43AN0CdbO/d+4DZwA5gPyLez0Hs04I41gDPB/uXBc+1Jfg5i4j3ZHBMLeB/wO/B7z4Q9v/VVPgJPQD/KeAfbu//WJWBH4CXIu5/ERgNHI59A/0IeDK4r37wYXUxdlV5DHBycN9I4A3gIOAIYApwc3Dfn/8pgcbBh4oE24cB27EEUSL4IPkXUAo4HlgCXBIc+zCwC2gdHHtAttd2IPahfEEOr/t6YFVw+3xgN/A8lhTOCz6wTorhHGT+7tPB7x4AlAfaBM9fDhgGjIx47vFk+2Dnr4ni9+D87ge8CwwN7qsQfPBdEdz39+Ac5JYoVgPXR/n7Vw2e+80g9tOwD91TgvvPABoGz1UVmA90zxb3/4Jzk5k8rwnOwX5AzyCGMsF992DvsZMACZ6vfPZzEGzXA34DGmAJ5jrs/Vo64r07E0s0B0Tsy3w/fwt0Cm6XBRpme837RTxXZ7Lek+WwpNgTKBNsNwj7/2oq/IQegP8U8A9n/7G2YN/uFPgSODS4T7APzMhvs2eR9c3xDeCFHB7zyODDJvLKowMwLrgd+Z9SsG94jYPtm4Cxwe0GwLJsj30/8FZw+2FgYpTXVjl4TSfncF9TYFdw+3zsw/6giPvfBx6M4RycD+zM/CDMJY66wIaI7fHknSj6RdzXDPgxuH0t8G3EfYIl2twSxS6Cq7xc7s/80KwcsW8K0D6X47sDI7LFfWEe77ENwGnB7QVAq1yOy54oXgMey3bMAuC8iPfuDTm8nzMTxUTgEaBCLq85t0TRAZgRz/93xfXH2weTW2tV/UJEzgMGY99aNwIVsW/F00Uk81jBvt2BfZP7JIfHOw7YH1gV8XslsA+0vaiqishQ7D/nROBqrLkk83EqicjGiF8piTUnZfrLY0bYAOwBjgZ+zHbf0Vgzy5/HqurWiO1fsKuavM4BwFpVTf/zTpEDgRewZHRYsLuciJRU1Ywo8UZaHXF7G/aNmCCmP19zcP5WRHmc9dhrLdDziciJ2JVWGnYe9sOu8iLt9TcQkZ5AlyBWBQ7G3lNg75nFMcQD9ve/TkTujNhXKnjcHJ87mxuBR4EfRWQp8IiqfhzD8+YnRpcP3pmdAlR1AvZt9tlg1zqsGaiWqh4a/Byi1vEN9p/0hBweajl2RVEh4vcOVtVauTz1EKCtiByHXUUMj3icpRGPcaiqllPVZpFhR3k9W7HmhytzuLsddvWU6TAROShiuwrwawznIKcYemJNKw1U9WCseQ0swUSNOQarsCsle0DLXpVzP5wvsGawgnoNS7I1gtfyAFmvI9Ofr0dEGmH9Bu2Aw1T1UKx5MvN3cnvP5GQ58ES2v/+Bqjokp+fOTlV/UtUOWNPn08AHwd84r/OfnxhdPniiSB0vAheLSF1V3YO1Xb8gIkcAiMgxInJJcGx/4HoRaSIiJYL7TlbVVdhIo+dE5ODgvhOCK5a/UNUZWMdvP2CMqmZeQUwB/hCR+0TkABEpKSK1ReTMfLyeXti30m4iUk5EDhORx7Hmo0eyHfuIiJQKPuxaAMNiOAc5KYcll40icjjwULb712D9LQXxX+BUEWkdjPS5HTgqyvEPAWeLyDMiclQQf3UReUdEDo3h+cphfSJbRORk4NYYjt+N/T33E5F/YVcUmfoBj4lIDTF1RKR8cF/28/ImcIuINAiOPUhEmotITKO1ROQaEakY/A0z31MZQWx7yP1v8DFwlIh0F5HSwfumQSzP6aLzRJEiVHUt8B+sfR7s2+EiYLKI/IF9Qz0pOHYK1in8AvatcQLWXADWll4KmIc1AX1A9CaQIcBFWNNXZiwZwGVYG/9S7Nt9P2xEVayv52vgEqzzdxXWpHQ6cK6q/hRx6Oogzl+xzuNbVDWzuSrXc5CLF7GO4XXAZOCzbPe/hF1BbRCRl2N9LcHrWYddIfXGmpVqYiN7duRy/GIsKVYF5orIJuyKbRrWL5WXu7HmwM3YB/d7eRw/BhtRthA71+ns3Tz0PNb/8zmWgPpj5wqsz+ltEdkoIu1UdRrWZ/UK9rdZhPUlxKop9pq3YOe8vaqmq+o2bPTZpOC5Gkb+kqpuxgZoXIa9L34CLsjH87pcZI5YcS7pBDN531HVaE04CUlESmDDczuq6riw43EuGr+icK6IiMglInKoiJQmq89gcshhOZenuCUKERkgIr+JyJxc7hcReVlEFgWlCerFKxbnEsRZ2KicdVjzSGtV3R5uSM7lLW5NTyLSGBvn/x9VrZ3D/c2AO7Gx5g2wyWLe8eSccwkmblcUqjoRm6Wam1ZYElFVnQwcKiKxjBt3zjlXhMKccHcMe4+qWBHsW5X9QBHpCnQFOOigg844+eSTiyRA55wraqqwdSukp9vt9HTYudP+3bULMmKd+hmowi8cykZms3udqlYsSExhJorsk38glwk1qtoX6AuQlpam06ZNi2dczjlXJH77DZYsgdGj4aef4PvvbTu70qXh2GPhkEOgcmVo2BBOOAGOOALKlYOyZUEk66eEqN0uIZR75zVKrv+NQ194+JeCxhlmoliBTbnPVBkbC++ccylpwwb4/HN49VWYNQs2bdr7/iOPhCuvhBYtoEYNOPpoqFQJSpXKx5OsXAm33gpXXQUdO8I/grmWLzxc4LjDTBSjgTuCekENgE3BzGDnnEt6CxbAxInw0UcwfTr8/rs1H0Xq0QNOOQUaNIDataHEvvQaq0K/fnD33dZG1bz5PsUfKW6JQkSGYBU6KwTFzx7CCs6hqq9jRemaYbM2t2EzhZ1zLqns2AHTpsGyZTBiBIwdC+vXZ91fpgxUqwb16kGjRlCrlt0+ujCH7ixeDDfdBOPGwQUXwJtvWttUIYlbogiKekW7P3PhFOecSwobNsD48ZYUJk2Cjz+G7REzYUqUsH6E006DSy+11p/atWG/eLfd/PCDXbb07QtdulhHRSHyMuPOORfF5Mn2+bt4sTUlZSpTxvoUTjgBrrsOjj8e0tJsf5GYM8d6v6+9Flq3tl7w8uXz/r0C8EThnHMRdu2yq4YRI+Cdd2BzUILx4IOhVSvraG7RwpJEIX9xj83OnfDvf9vPkUdCu3aWneKUJMAThXOumJs7F2bPtquF//wHtm3Luu/oo6FDB3j0UftMDt1338GNN1rQ11wDL7xQJJcwniicc8XKzz9b5/Onn8KAAXvfV7kytGwJp55qTf1HHBFKiDlbudJ6w4880jpHCnFUU148UTjnUtrWrfDKK9Cnjw1PXbs2677jjoPq1eGxx+Ckk+Dww8OLM1cLF8KJJ8Ixx8B770GTJtYOVoQ8UTjnUs6qVfD44zBs2N6JoV49uPdem9l86qk2QilhbdxowfbrZ50mjRvD5ZeHEoonCudcSkhPt+akvn1t9vOePdZ0dOWV1px/2WUhdT4XxOjRNrt69Wq45x44Mz+rCBc+TxTOuaQ1f771N4wcCR9+aPtKl7bP1RdftCuHpNOlC/Tvb5c8o0bZmNuQeaJwziWVPXvgtdesRWbmTNu33372edqhA9xyCxx4YLgx5lvmukAi9kKOOw7uuy+fRZ7ixxOFcy5hqdpEt7fftpGhO3bAt9/aXAeASy6B+++3WklFNtGtsC1fbtmtfXvo1MluJxhPFM65hLJtm1Wj+OQTePdd+xzNVKkS3HCDJYaOHRPmC3fB7NkDb7xhVw4ZGaF1VMfCE4VzLnQ7dsDrr9sw1kWLsvaffjp07w4XX2w1k5KmMzovP/1kfRETJ8JFF1kPfLVqYUeVK08UzrlQzJplTUoTJljJokwXXWTF9C66CKpWDS28+Jo3z6aDDxgAnTsnfAb0ROGcKzJDhtgIpf/9zyqxZmrWzGZEd+qUhB3RsZo1y3rfr7vOikYtWQKHHRZ2VDHxROGci6uMDGtSevppmwgHcMYZcP750K2bLfGZ4F+o982OHTb776mnrHjUVVdZz3uSJAnwROGci4O1a6F3b+uQXrTICp4eeST07AmPPAIHHRR2hEXk22+tiN/8+VYO/Pnnk3J4licK59w+270bxoyxkhlvv733fc2awfXXwxVX7ONSn8lm5Uo47zw46ijLmJdeGnZEBeaJwjlXYJMm2ZfkzFnRAIcemjV8tUOHIljdLdHMn28LYR9zDLz/vhXxK1cu7Kj2SXH7Ezrn9tGMGXDnnbBmTdZQ1vr1bb5YmzZQpUq48YVmwwZrW3vrLRv22qiRrTyXAjxROOdiMmuW1an79lvbPvxweOIJ6NoVKlQIN7bQjRgBt91mnTP33x96Eb/C5onCORfVvHnwr3/B8OG23bKljWI69thw40oYN9xgVxF168J//2u1zFOMJwrn3F9kZNh60R9+aBWvwUp19+oFtWqFG1tCiCzi17Ah1KgBd98N++8fblxx4onCOQfYOjmffgqDB9tKm5luvBFuvjnlWlMK7pdf7IRcfbUNee3aNeyI4s4ThXPF2KZNNlP6iSes/FCmBg2gbVv7PEzyATuFJ7O+ea9edkVx5ZVhR1RkPFE4V8xs2WKlNLp3t0qtYMmgdWurU3fxxUlelTUeFiywk/P11/C3v1nV15QtRPVXniicKwY2boQXXoBx4+Crr2xfxYrW/3rLLVZVwpNDFAsWwNy5MHCgNTeldM2Rv/JE4VwKGz8ennzSvghnXj2ce67VWGrbtth93uXPjBlWxO/6622o15IlNpuwGPJE4VwKUbVhrJ9/Dt98Y1+Cy5SxEZuPPgoXXujJIU/p6Xayeve22dUdOthJLKZJAjxROJcStmyBoUPhppv23v/gg3DvvVC2bDhxJZ1Jk2yY14IFdiXx3HNJWcSvsHmicC6J7dxpK2m++KJtH364lde45RarRefyYeVKuOACu4oYM8Y6rR3gicK5pPTzz/DYY7ZAGsBxx8EDD1g/q38Bzqd586BmTUsQw4dbsvBLsL14onAuSSxcaDOlBw2yzzaA6tVtOP/jjxezEt6F4fff4a67stZjbdwYLrss7KgSkicK5xLYDz/YqKWvvoIVK2xf9erWfH7zzTYxzhXA8OFw++2wfj384x9W/tblyhOFcwlG1apUP/SQfdEFm/Nw443w97/DqaeGG1/S69zZriLq1YPPPrPJJC4qTxTOJYidOy05vPmmfdEFaNrUKreedVa4sSW9yCJ+Z59tCwv17FkMV1UqmLi2aopIUxFZICKLRKRXDvdXEZFxIjJDRGaLSLN4xuNcIvr+e2sFKV0annoKKlWCl1+2ZPHpp54k9tnSpTaC6T//se2uXW2omCeJmMXtTIlISaAPcDGwApgqIqNVdV7EYf8E3lfV10SkJvAJUDVeMTmXSH74wQqQzplj282aweWXW0khVwgyMqBPH1tIqEQJW5vVFUg8U2p9YJGqLgEQkaFAKyAyUShwcHD7EODXOMbjXEL48ktbDG3hQttu0MBGMtWoEW5cKWX+fOvU+fZbuPRSeP31YrxG676LZ9PTMcDyiO0Vwb5IDwPXiMgK7GrizpweSES6isg0EZm2du3aeMTqXFypWkmNM8+Eiy6yJHHzzdYqMnmyJ4lCt2iRza4eNMhWnfMksU/imShyqiij2bY7AANVtTLQDBgkIn+JSVX7qmqaqqZVrFgxDqE6Fz+vvmoDbM45x5qbOneGVavsS24xqlQdf9OnZ81AvOwyy8LXXOPFrQpBPJueVgCRq+pW5q9NSzcCTQFU9VsRKQNUAH6LY1zOxd2uXdC/v02EW7nS9r3wAnTqBOXLhxtbytm+HR55BJ591hbyvvpqm55+8MF5/66LSTyvKKYCNUSkmoiUAtoDo7MdswxoAiAipwBlAG9bcklJ1dZ7uPBCW9vh1lstSdx4o5X47t7dk0ShmzgRTjsNnn7aLtVmzPAaJnEQtysKVd0tIncAY4CSwABVnSsijwLTVHU00BN4U0R6YM1SnVU1e/OUcwlt4kS7ehg5Ev74w/bVrm0d1l26wP77hxtfylq5Epo0sauIL76w2y4uJNk+l9PS0nTatGlhh+GKuQ0bbHLvQw9lJYcTT7TSGu3be99DXP3wQ9b09I8/tiJ+Bx0UbkxJQESmq2paQX7Xy4g5lw9Ll0KbNlattUcPqFDB6sqtWWODbHr18iQRN+vWWSdPnTp2GQfQooUniSLgUxOdi8F339mVws8/23bNmvDaa9CokQ+qiTtVGDYM7rjDLuUeesirIRYxTxTO5UIV+vWzftLFiy0hVK8O77zjn1NF6rrrbD5EWprNVvSqiEXOE4Vz2fz8syWIJ56w7SOOsKuJl16y264IRBbxO+88a27q3t3rM4XEz7pzgdWrba5D7962Xa8edOhgfRElS4YbW7GyZIkt/n3NNTY64MYbw46o2PPObFfsffyxVZ4++mhLEk2b2nyI6dPh7rs9SRSZjAxb/PvUU2HqVF+yL4H4FYUrljL7R++8E34L6gCcdx7ccIOtO+2K2Lx5dvK/+w6aN7f6JpUrhx2VC3iicMXK7t3w0UdW8WHWLDjsMCvO9+yzULZs2NEVY0uX2oiBwYOtQ8iHkiUUTxSuWNi5076k9uxpyaJcOfjnP+GBB+CAA8KOrpiaOhVmzrT+iObNrW+iXLmwo3I58EZAl9I2brT+0NKlbb3pkiXhuedg7Vp47DFPEqHYts06fxo2hCefhPR02+9JImF5onApadcuSwyVK8PAgTb/4bXXYNMmm0ldunTYERZT48fbUNfnnrMrCS/ilxS86cmlnC++sCWSVa0g34QJ0Lhx2FE5VqyAiy+2+idjx1qNJpcU/IrCpYT0dFse+eST7bOodGm45x7b70kiZLNm2b+VK8OoUTB7tieJJOOJwiU1VZsHUaOGlQJasACuuspWwuzd24fih2rtWltEqG5du6wDaNYMDjww3Lhcvvl/I5eUtmyxUUxpabbqZUYGvPIKbN4MQ4fCMdlXZ3dFRxWGDLHKiR98YGORzzor7KjcPoipjyJYoa6Kqi6KczzORbV+vQ1rHTgwa7BMjx5Wl8lHMCWITp3g3XetcmL//lCrVtgRuX2UZ6IQkebA80ApoJqI1AUeUtXL4x2cc5m+/NKSwzvv2PaFF8J999kIS18aOQHs2WOT5ESs/+GMM6BbN69/kiJiuaJ4FGgAjANQ1ZkiUj2uUTkXWLbMasJ98YVtX3ONrUV99tnhxuUiLFpkQ107dbIyHF7EL+XE0kexS1U3ZtuXXOunuqSjavMejjvOksSJJ1qVh0GDPEkkjN27rfbJqafafIhSpcKOyMVJLFcU80WkHVBCRKoBfwcmxzcsV5zNmAGtWsHy5basaK9eVo/JJZA5c2zK+7Rp9sd69VWoVCnsqFycxHJFcQdwBrAH+BBIx5KFc4Xqk0+sz6FePUsSd9wBP/3kSSIhLVsGv/xiQ8xGjPAkkeJiuaK4RFXvA+7L3CEiV2BJw7l9sno1vP22DW1dscL23XSTjWyqUiXc2Fw2331nk+e6drX5EEuWeMndYiKWK4p/5rDvH4UdiCte3nsP6te3xYJ69bJ5Effea/Mg+vb1JJFQtm61AllnnWWzGHfssP2eJIqNXK8oROQSoClwjIg8H3HXwVgzlHP5tmOHLS86YoRtd+sGLVpAkyY+izohjR1rl3hLlthws6ee8oqKxVC0pqffgDlYn8TciP2bgV7xDMqlnj17bIJunz42ae7oo21UpVdzSGArVsAll0C1al5ZsZjLNVGo6gxghoi8q6rpRRiTSzGDB1vH9IYNcNBBVheuZcuwo3K5mjEDTj/divh99JGtEevT3ou1WC72jxGRoSIyW0QWZv7EPTKX9ObOhdq1oWNHG3L/2GOWLDxJJKg1a6yiYr16WUX8mjb1JOFiShQDgbcAAS4F3geGxjEml+Q2bYLbbrMksWiRTdZdtsxGMu2/f9jRub9QtdooNWvCyJHw+OM+q9HtJZbhsQeq6hgReVZVFwP/FJGv4h2YSz6//WYLl735pl051KsHb71lC5q5BHb11TYf4qyzrIjfKaeEHZFLMLEkih0iIsBiEbkFWAkcEd+wXDJZuRJeegmeeca269SxNSL8S2kCiyzi97e/WZK4/XYv4udyFEvTUw+gLNANOAe4CbghnkG55LBrFzz4oPV5PvOMtVyMGmVzsjxJJLCFC63C64ABtn399V7p1UWV5xWFqn4X3NwMdAIQkcrxDMoltt27rYXi2WetD+LUU22SXMOGYUfmotq9G55/Hh56CMqU8U5qF7OoiUJEzgSOAb5W1XUiUgsr5XEh4MmiGBoxAh54AH780SbI9e1r87Fcgps920YVTJ8Ol19uE1qOPjrsqFySyLXpSUSeBN4FOgKficg/sDUpZgEnFk14LlF8843Nt7riCksSffrYCnOeJJLEihVWaXHYMBg+3JOEy5doVxStgNNUdbuIHA78GmwviPXBRaQp8BJQEuinqk/lcEw74GFsjYtZqnp1PuJ3cfb111bmZ+pU277iCqsofeSR4cblYvDNN3YlccstWUX8Djoo7KhcEorWmZ2uqtsBVPV34Md8JomSQB9s7kVNoIOI1Mx2TA3gfuAcVa0FdM9n/C5Otm61hcoaNbIkce+99pkzfLgniYS3ZQv8/e9w7rk2XjmziJ8nCVdA0a4ojheRzFLiAlSN2EZVr8jjsesDi1R1CYCIDMWuUuZFHHMT0EdVNwSP+Vs+43dxsGmTfQH95hs480x4/31bQMglgc8/tzLgy5bZcNd//9uL+Ll9Fi1RtMm2/Uo+H/sYYHnE9gps7e1IJwKIyCSseephVf0s+wOJSFegK0AVrz8dV2+8Ad27W//DM8/A3XeHHZGL2fLl0Lw5nHACTJxoVxTOFYJoRQG/3MfHlpweNofnrwGcj42i+kpEamdfo1tV+wJ9AdLS0ny97jh5+GGr8Hr00TaaqUWLsCNyMZk+Hc44A4491pYJbNTIhr86V0jiuQLACuDYiO3KWId49mNGqeouVV0KLMAShytCGRlWxeGRR+Ccc6wvwpNEEli9Gq68EtLSsor4XXyxJwlX6OKZKKYCNUSkmoiUAtoDo7MdMxK4AEBEKmBNUUviGJPLZt06q94wZIhVcpgwASpUCDsqF5WqrR9bs6aVAf/3v30qvIurmBOFiOSrR0xVdwN3AGOA+cD7qjpXRB4VkcxC02OA9SIyD5ujcY+qrs/P87iC2bHDKkhXrGijmtq2hc8+8yoOSaF9e+jc2RLFzJlw//1eltfFlahGb/IXkfpAf+AQVa0iIqcBXVT1zqIIMLu0tDSdNm1aGE+dEnbtsnLfmRVe69aFJ5+0pOESWGQRv7fftsXFb7vN1491MROR6aqaVpDfjeVd9jLQAlgPoKqzCJqLXHIZPNg6qnv3tiQxcKAtZuZJIsH9+KNNi+/f37avu86WDPQk4YpILO+0Eqr6S7Z9GfEIxsVHRoZ9+ezY0ZqWBg+2fdddF3ZkLqpdu6z/4bTTYN48KFs27IhcMRXLehTLg+YnDWZb3wn4UqhJYvp0qwU3e7ZdOQwb5p83SWHmTCv/PXOmdSD93//BUUeFHZUrpmJJFLdizU9VgDXAF8E+l+DGjMlqVnr2WejRw1srksbq1fYzfLgV2HIuRLEkit2q2j7ukbhCNWqUzY0oV85KcdSuHXZELk9ff22XfrfdZhl+8WI48MCwo3Iupj6KqSLyiYhcJyLl4h6R22cjRkDr1jbvaupUTxIJb/Nm65xu1AhefDGriJ8nCZcg8kwUqnoC8DhwBvCDiIwUEb/CSFAvvmgtFaVLw4IFcNJJYUfkohozxjL5q69axdfvv/cifi7hxNRirarfqGo3oB7wB7agkUsww4dbP0S5cvZ54zOsE9zy5VYr5cADrdnpxRd9pIFLSHkmChEpKyIdReQjYAqwFvB6AQlk5UpbO6JtWysHvny5Tdp1CUgVpkyx28ceC59+apNZvASHS2CxXFHMARoCvVW1uqr2VNXv4hyXi9GgQVC5MgwYYLWaJk+GQw4JOyqXo1WroE0baNAgq4jfRRd5ET+X8GIZ9XS8qu6JeyQuX7ZsgVtvhXfegeOOg1de8YqvCUvVpsHfdZct9PH001am17kkkWuiEJHnVLUnMFxE/lIQKoYV7lycfP21VZdevdoGyzz9tA+QSWjt2sEHH9iopn794MQTw47IuXyJdkXxXvBvfle2c3F0//0t09WHAAAenElEQVTw1FN2O3MYrEtAGRlWwK9ECbjsMrjwQrj5Zp/x6JJSru9aVQ163DhFVb+M/AFOKZrwXKbt262iw1NPWX24GTM8SSSs+fPt6iGziN+111o7oScJl6RieefekMO+Gws7EJe7d9+1pqWBA6FlSxt6X7du2FG5v9i1Cx5/3P44Cxb4qAKXMqL1UVyFrUpXTUQ+jLirHLAx599yhe2f/4QnnrCBMY8/Dj17hh2Ry9GMGbaY0OzZcNVV8PLLcMQRYUflXKGI1kcxBVuDojLQJ2L/ZmBGPINy1nrRujUsXAi1alkVWJ+wm8DWrLF1ZUeOhFatwo7GuUKVa6JQ1aXAUqxarCtC77wDnTpBqVLQvbstNOQrXSagiRPhhx/g9tutiN+iRXDAAWFH5Vyhy7WPQkQmBP9uEJHfI342iMjvRRdi8aEKt9xiSaJGDSvD8cILniQSzh9/WIXX886zJqbMIn6eJFyKitaZnbncaQWgYsRP5rYrRKrQrRu88QY0b25VHmrVCjsq9xeffGJ/mDfesAl0XsTPFQPRmp4yZ2MfC/yqqjtF5FygDvAOVhzQFZIbbrBRTZdeas3c+8UyZ94VreXLrf/hpJNsAl2DBmFH5FyRiGV47EhsGdQTgP9gcygGxzWqYmTPHmveHjjQajWNHu1JIqGoWgEtsCJ+n39uVxGeJFwxEkui2KOqu4ArgBdV9U7gmPiGVTxs2gQlS9q8iPPPh48+8iSRUH791YaenXVWVhG/Cy6wUQbOFSOxJIrdInIl0An4ONjn3av76LPPoFo1u33SSTB2rH/+JAxVq8lUs6ZdQTz7rBfxc8VarDOzL8DKjC8RkWrAkPiGldpeftn6IkqUsKuJH3+0skAuQbRtCzfdZDOsf/jBZjn6pZ4rxvJ896vqHBHpBlQXkZOBRar6RPxDSz1//GEDZfr3h7Q0u6ooXz7sqBywdxG/1q2tw+imm7w+k3PEtsJdI2AR0B8YACwUEb8Oz6evvrJ1I/r3t6rTEyd6kkgYc+ZY01JmEb9OnbzSq3MRYvmf8ALQTFXPUdWzgebAS/ENK7X06mUVXzdtspXo3nvP52YlhJ074ZFHoF49WLwYDjss7IicS0ixNLyWUtV5mRuqOl9EvNs1Rtdea8uVnnwyDB/ua1knjOnTrYjfnDlw9dXw4otQ0eeROpeTWBLF9yLyBjAo2O6IFwXM05490KWLJQmAmTN9Am9CWb8eNm60Mcm+hqxzUcWSKG4BugH3AgJMBP4vnkElu23brKlp+nSoUwf++19PEglh3DgbxdStm3VW//ST1W93zkUVtY9CRE4FmgIjVLWlql6mqs+oanrRhJd8fvsN6te3JNGjh11JVK4cdlTF3KZN1jl94YXw2mtZRfw8STgXk2jVYx/Aynd0BP4nIjmtdOciTJ5sVV/nzbP5Ws8/7/MjQvfRR9Yx1K8f3H23L+zhXAFEa3rqCNRR1a0iUhH4BBse67LZsgVeeslWoytb1ibRXXxx2FE5li+HNm1sJMHIkXDmmWFH5FxSipYodqjqVgBVXSsiPqg8B6tXQ8OG8MsvNolu6FA44YSwoyrGVOHbb+Hss7OK+J19ttdHcW4fRPvwP15EPgx+RgAnRGx/GOX3/iQiTUVkgYgsEpFeUY5rKyIqImn5fQFhWrrUioj+8gu88gpMnepJIlQrVkDLljZ5LrOI3/nne5Jwbh9Fu6Jok237lfw8sIiUxNbavhhYAUwVkdGRczKC48pho6q+y8/jh23pUmjUyEZZDh8OV1wRdkTF2J498OabcM89sHu3dQ6de27YUTmXMqItXPTlPj52fawu1BIAERkKtALmZTvuMaA3cPc+Pl+RGTnS5mpt2gSffmrrSbgQtWljf5QLL7SEcfzxYUfkXEqJZ7/DMcDyiO0VZFvHQkROB45V1Y+JQkS6isg0EZm2du3awo80H+69Fy6/3CbxTp7sSSI0u3fblQRYonjzTfjiC08SzsVBPBNFTgND9c87rXP8BaBnXg+kqn1VNU1V0yqGWGbh+efhmWfgkEPgm298kbPQzJ5tiwm9+aZtX3ONTYP3scjOxUXMiUJE8jv4fAW23namysCvEdvlgNrAeBH5GWgIjE7EDu2MDOje3ZYlaNDARjp5WaAQ7NgBDz0EZ5xhIwj8j+BckYilzHh9EfkB+CnYPk1EYinhMRWoISLVgiKC7YHRmXeq6iZVraCqVVW1KjAZaKmq0wryQuKpY0ebJ9GwIXz5pU/oDcXUqVbl9dFHoUMHmD/fRxA4V0RiqfX0MtACm6WNqs4SkQvy+iVV3S0idwBjgJLAAFWdKyKPAtNUdXT0R0gMl10GH39spYE++8xbN0KzYYPNbPzkE1se0DlXZGJJFCVU9RfZ+xMyI5YHV9VPsBndkfv+lcux58fymEVl0yYbkj9xIhxzDAwb5kmiyI0da0X8/v53y9QLF3r5DedCEEsfxXIRqQ+oiJQUke7AwjjHFaodO2yOxMSJNsJp/nw4+OCwoypGNm60ZUibNIE33sgq4udJwrlQxJIobgXuAqoAa7BO51vjGVSYdu6E9u3ti+zrr8OHH0K5cmFHVYyMGmVF/AYMsLHIXsTPudDl2fSkqr9hHdHFQufONnerWzerTO2K0LJlcOWVcMopMHq0Fc9yzoUuz0QhIm8SMf8hk6p2jUtEIfriCxgyBC65xEY5uSKgCl9/bW19VarYH6FhQ6/P5FwCiaXp6Qvgy+BnEnAEsCOeQYXhk0+geXObTPdKvqpauQJbtsxOeuPGWUX8Gjf2JOFcgoml6em9yG0RGQT8L24RhWDkSOu0LlnShutXrx52RCluzx7rALrvPruiePllL+LnXAIrSAmPasBxhR1IWAYMsCRRtaotoVyjRtgRFQNXXAG3325lOObMgTvvtCztnEtIsfRRbCCrj6IE8DuQ69oSyWTMGLjxRrv91Ve+tnVc7d4NJUrYz1VXQatWNnLAJ6c4l/CiJgqxWXanASuDXXtU9S8d28lowgRo1gwqVIARIzxJxNWsWXDDDTY34pZbrASHcy5pRG16CpLCCFXNCH5SIkmsWQMtWsBBB8G0ad48Hjfp6baQeFqarT531FFhR+ScK4BYSnhMEZF6qvp93KMpAhkZtr7Nli3w3//CcSnT25JgpkyB666DH3+0f59/Hg4/POyonHMFkGuiEJH9VHU3cC5wk4gsBrZi60yoqtYrohgL1UMPwbx5Vj6oWbOwo0lhf/wB27dbJcVLLgk7GufcPpDcWpNE5HtVrSciJ+R0v6oujmtkuUhLS9Np0wpWifybb+Ccc+DMM211uhLxXLapOPr8c5g7F3r0sO0dO7z8hnMJQkSmq2qByh1Ea3oSCC8hFLbt220u1/77W9lwTxKFaMMGuOsuGDgQatWC226zBOFJwrmUEC1RVBSRu3K7U1Wfj0M8cXPHHdY/8cwzcMQRYUeTQj780OZErF0L998P//qXJwjnUky0RFESKEvOa18nlUGDbGLdtddmtYq4QrBsmZXarV3baqCcfnrYETnn4iBaolilqo8WWSRxsmSJJYjTToO+fcOOJgWo2kId551nRfzGjrWFxPffP+zInHNxEq2lPumvJAAuusj+7dfPW0T22S+/2DKk55+fVcTv3HM9STiX4qIliiZFFkWcPPMMLF1qk4J9aYN9sGePldStVctKgv/f/1lZcOdcsZBr05Oq/l6UgRS2HTuy1pR47bVwY0l6rVvDRx/ZfIg33vBZis4VM7HMzE5Kjz8OK1fC8OG+vEGB7NplFV1LlLDaTG3bQqdOXsTPuWIoJWcTrFtnieKcc6yitcun77+H+vVtzQiwRHHttZ4knCumUjJR3Huv/fvAA+HGkXS2b7e5EPXrw+rVcOyxYUfknEsAKdf0dOed8NZbcPXVXsspXyZPtuJ9Cxda7/+zz8Jhh4UdlXMuAaRUoli1ygbnHHggvP122NEkma1brV/if//LGlPsnHOkWKL417/s3/ffh/1S6pXFyWefWRG/nj2hSRMrCe49/865bFKmj+LLL21SXbt20Lx52NEkuPXrrZnp0kvt0mvnTtvvScI5l4OUSRS33GL/vvpquHEkNFX44AOoWRMGD7bV56ZO9QThnIsqJRpoPvwQFi2yPtjy5cOOJoEtW2a9/HXq2NoRp50WdkTOuSSQ9FcUixfbPLCKFaFPn7CjSUCqVrgPbEb1+PE2wsmThHMuRkmfKG6+GbZts/Wvy5QJO5oEs3Qp/O1v1lGdWcTv7LO9p985ly9JnShGjbJO7EsvteVNXSAjwwpd1a4N331nxa68iJ9zroCS+qtlv37276BB4caRcFq1skusZs2sDIfPsHbO7YOkTRTffGNrX19/vXdgA3sX8evUyeozXX2112dyzu2zuDY9iUhTEVkgIotEpFcO998lIvNEZLaIfCkiMdevzqxXd//9hRdv0po2zRbcyKynftVV0LGjJwnnXKGIW6IQkZJAH+BSoCbQQURqZjtsBpCmqnWAD4DesTz21q02JPbSS6FGjcKMOsls3w733WdLka5d6+tEOOfiIp5XFPWBRaq6RFV3AkOBVpEHqOo4Vd0WbE4GKsfywCNGWLLo0qVQ400u335rQ1x797YJJPPmQYsWYUflnEtB8eyjOAZYHrG9AmgQ5fgbgU9zukNEugJdAapUqcLMmbb/vPMKI8wktX27LVH6xRc2/NU55+IknokipwZyzfFAkWuANCDHj35V7Qv0BUhLS9Nhw+CEE4phJ/Ynn1gRv3vugQsvhPnzYf/9w47KOZfi4tn0tAKIHJdZGfg1+0EichHwD6Clqu7I60F37LBKFBdcUGhxJr516+Caa6za4bvvZhXx8yThnCsC8UwUU4EaIlJNREoB7YHRkQeIyOnAG1iS+C2WB92wwf4tFs3xqjB0KJxyitVOf+ghmDLFi/g554pU3JqeVHW3iNwBjAFKAgNUda6IPApMU9XRwDNAWWCY2FDOZaraMtrjbtli/zZtGq/IE8iyZVYO/LTToH9/OPXUsCNyzhVDoppjt0HCKlUqTc8+exrjx4cdSZyoWl2SzFXmJk+2+iQlS4Ybl3MuqYnIdFVNK8jvJl2tp127Uni00+LFNoLp4ouzivg1bOhJwjkXqqRLFAD16oUdQSHLyIDnn7empenT4Y03vIifcy5hJGWtp9NPDzuCQnbZZfDpp9ZD/9prUDmmeYfOOVckkq6PQiRNVaeFHca+27nT1oUoUcJGNGVkQPv2Xp/JORcXxaqPIiU+R6dMgTPOyFrgu107q/aaEi/OOZdqki5RJNkF0N62bYOePeGss2xCyAknhB2Rc87lKen6KJJ2Fc+vv7Y5EUuW2PqtTz8NhxwSdlTOOZenZP3YTT6ZCwuNGwfnnx92NM45FzNPFPH00UdWuO/ee6041bx5SXxJ5JwrrpKujyIprF1ry5C2bAlDhmQV8fMk4ZxLQp4oCpMqDB5sRfw++AAefRS++86L+DnnklrSfcVN6BGky5bB9dfbjMD+/aFWrbAjcs65feZXFPtqzx4YM8ZuH3ccfPUVTJrkScI5lzI8UeyLn36yleaaNoWJE21f/fpexM85l1I8URTE7t3wzDNQpw7MnGnNTF7EzzmXopKujyIhtGhhzU2tWlkZjkqVwo7IuYS0a9cuVqxYQXp6etihFBtlypShcuXK7F+ISyUnXVHAUqXSdOfOEIoC7thha1SXKGEjmvbsgSuvTPDedefCtXTpUsqVK0f58uUR/78Sd6rK+vXr2bx5M9WqVdvrvmJVFDAUkyfbIhh9+th227ZWyM/f+M5FlZ6e7kmiCIkI5cuXL/QruKRLFEX6ftu6FXr0gLPPhs2boUaNInxy51KDJ4miFY/z7X0UufnqKyvit3Qp3HYbPPkkHHxw2FE551yRS7oriiKze7f1SUyYYE1OniScS1ojRoxARPjxxx//3Dd+/HhatGix13GdO3fmgw8+AKwjvlevXtSoUYPatWtTv359Pv30032O5cknn6R69eqcdNJJjMmcg5VNo0aNqFu3LnXr1qVSpUq0bt0agFGjRlGnTh3q1q1LWloaX3/99T7HEwu/oog0cqQV8bv/fiviN3eu12dyLgUMGTKEc889l6FDh/Lwww/H9DsPPvggq1atYs6cOZQuXZo1a9YwYcKEfYpj3rx5DB06lLlz5/Lrr79y0UUXsXDhQkpmm3v11Vdf/Xm7TZs2tGrVCoAmTZrQsmVLRITZs2fTrl27vZJfvPinIMCaNXDnnTBsmHVa9+xp9Zk8SThXaLp3t2lHhaluXXjxxejHbNmyhUmTJjFu3DhatmwZU6LYtm0bb775JkuXLqV06dIAHHnkkbRr126f4h01ahTt27endOnSVKtWjerVqzNlyhTOOuusHI/fvHkzY8eO5a233gKgbNmyf963devWIuv/Kd5NT6owaBDUrAmjRsETT9gIJy/i51zKGDlyJE2bNuXEE0/k8MMP5/vvv8/zdxYtWkSVKlU4OIYm5x49evzZTBT589RTT/3l2JUrV3Lsscf+uV25cmVWrlyZ62OPGDGCJk2a7BXHiBEjOPnkk2nevDkDBgzIM77CULy/Mi9bBl26QFqaza4++eSwI3IuZeX1zT9ehgwZQvfu3QFo3749Q4YMoV69erl+G8/vt/QXXngh5mNzmrcW7fmGDBlCly5d9tp3+eWXc/nllzNx4kQefPBBvvjii9iDLaCkSxT7fKWVWcTv0kutiN+kSVbt1eszOZdy1q9fz9ixY5kzZw4iQkZGBiJC7969KV++PBs2bNjr+N9//50KFSpQvXp1li1bxubNmylXrlzU5+jRowfjxo37y/727dvTq1evvfZVrlyZ5cuX/7m9YsUKKuVS2WH9+vVMmTKFESNG5Hh/48aNWbx4MevWraNChQpRY9xnqppUP6VLn6EFtmCBaqNGqqA6fnzBH8c5F5N58+aF+vyvv/66du3ada99jRs31okTJ2p6erpWrVr1zxh//vlnrVKlim7cuFFVVe+55x7t3Lmz7tixQ1VVf/31Vx00aNA+xTNnzhytU6eOpqen65IlS7RatWq6e/fuHI997bXX9Nprr91r308//aR79uxRVdXp06drpUqV/tyOlNN5B6ZpAT93i0cfxe7d8PTTVsTvhx/grbegceOwo3LOxdmQIUO4/PLL99rXpk0bBg8eTOnSpXnnnXe4/vrrqVu3Lm3btqVfv34ccsghADz++ONUrFiRmjVrUrt2bVq3bk3FihX3KZ5atWrRrl07atasSdOmTenTp8+fI56aNWvGr7/++uexQ4cOpUOHDnv9/vDhw6lduzZ169bl9ttv57333iuSDu2kq/VUpkyapqfns9bTJZfA55/DFVfYnIijjopPcM65vcyfP59TTjkl7DCKnZzO+77Uekq6PoqYpafbhLmSJaFrV/tp0ybsqJxzLumkZtPTpEk2wDqziF+bNp4knHOugFIrUWzZAt262SJC6engl7zOhS7ZmreTXTzOd9Ililz7bSZMgNq14ZVX4I47YM4cuPjiIo3NObe3MmXKsH79ek8WRUSD9SjKlClTqI+bWn0UBx5oVV/POSfsSJxz2LyBFStWsHbt2rBDKTYyV7grTEk36umAA9J0+/Zg1NOHH8KPP8IDD9h2RoZPnHPOuRwk7Ap3ItJURBaIyCIR6ZXD/aVF5L3g/u9EpGpMD7x6ta0y16YNjBgBO3fafk8SzjlX6OKWKESkJNAHuBSoCXQQkZrZDrsR2KCq1YEXgKfzetxDM9ZbJ/XHH9tiQt9840X8nHMujuJ5RVEfWKSqS1R1JzAUaJXtmFbA28HtD4Amksc0w0q7frFO61mzoFcvmyvhnHMubuLZmX0MsDxiewXQILdjVHW3iGwCygPrIg8Ska5A12Bzh3z99Ryv9ApABbKdq2LMz0UWPxdZ/FxkOamgvxjPRJHTlUH2nvNYjkFV+wJ9AURkWkE7ZFKNn4ssfi6y+LnI4ucii4jks/ZRlng2Pa0Ajo3Yrgz8mtsxIrIfcAjwexxjcs45l0/xTBRTgRoiUk1ESgHtgdHZjhkNXBfcbguM1WQbr+uccykubk1PQZ/DHcAYoCQwQFXnisijWF300UB/YJCILMKuJNrH8NB94xVzEvJzkcXPRRY/F1n8XGQp8LlIugl3zjnnilbS1XpyzjlXtDxROOeciyphE0Xcyn8koRjOxV0iMk9EZovIlyJyXBhxFoW8zkXEcW1FREUkZYdGxnIuRKRd8N6YKyKDizrGohLD/5EqIjJORGYE/0+ahRFnvInIABH5TUTm5HK/iMjLwXmaLSL1Ynrggi62Hc8frPN7MXA8UAqYBdTMdsxtwOvB7fbAe2HHHeK5uAA4MLh9a3E+F8Fx5YCJwGQgLey4Q3xf1ABmAIcF20eEHXeI56IvcGtwuybwc9hxx+lcNAbqAXNyub8Z8Ck2h60h8F0sj5uoVxRxKf+RpPI8F6o6TlW3BZuTsTkrqSiW9wXAY0BvIL0ogytisZyLm4A+qroBQFV/K+IYi0os50KBg4Pbh/DXOV0pQVUnEn0uWivgP2omA4eKyNF5PW6iJoqcyn8ck9sxqrobyCz/kWpiOReRbsS+MaSiPM+FiJwOHKuqHxdlYCGI5X1xInCiiEwSkcki0rTIoitasZyLh4FrRGQF8AlwZ9GElnDy+3kCJO7CRYVW/iMFxPw6ReQaIA04L64RhSfquRCRElgV4s5FFVCIYnlf7Ic1P52PXWV+JSK1VXVjnGMrarGciw7AQFV9TkTOwuZv1VbVPfEPL6EU6HMzUa8ovPxHlljOBSJyEfAPoKWq7iii2IpaXueiHFAbGC8iP2NtsKNTtEM71v8jo1R1l6ouBRZgiSPVxHIubgTeB1DVb4EyWMHA4iamz5PsEjVRePmPLHmei6C55Q0sSaRqOzTkcS5UdZOqVlDVqqpaFeuvaamqBS6GlsBi+T8yEhvogIhUwJqilhRplEUjlnOxDGgCICKnYImiOK7POhq4Nhj91BDYpKqr8vqlhGx60viV/0g6MZ6LZ4CywLCgP3+ZqrYMLeg4ifFcFAsxnosxwN9EZB6QAdyjquvDizo+YjwXPYE3RaQH1tTSORW/WIrIEKypsULQH/MQsD+Aqr6O9c80AxYB24DrY3rcFDxXzjnnClGiNj0555xLEJ4onHPOReWJwjnnXFSeKJxzzkXlicI551xUnihcwhGRDBGZGfFTNcqxVXOrlJnP5xwfVB+dFZS8OKkAj3GLiFwb3O4sIpUi7usnIjULOc6pIlI3ht/pLiIH7utzu+LLE4VLRNtVtW7Ez89F9LwdVfU0rNjkM/n9ZVV9XVX/E2x2BipF3NdFVecVSpRZcb5KbHF2BzxRuALzROGSQnDl8JWIfB/8nJ3DMbVEZEpwFTJbRGoE+6+J2P+GiJTM4+kmAtWD320SrGHwQ1Drv3Sw/ynJWgPk2WDfwyJyt4i0xWpuvRs85wHBlUCaiNwqIr0jYu4sIv9XwDi/JaKgm4i8JiLTxNaeeCTY1w1LWONEZFyw728i8m1wHoeJSNk8nscVc54oXCI6IKLZaUSw7zfgYlWtB1wFvJzD790CvKSqdbEP6hVBuYargHOC/RlAxzye/zLgBxEpAwwErlLVU7FKBreKyOHA5UAtVa0DPB75y6r6ATAN++ZfV1W3R9z9AXBFxPZVwHsFjLMpVqYj0z9UNQ2oA5wnInVU9WWsls8FqnpBUMrjn8BFwbmcBtyVx/O4Yi4hS3i4Ym978GEZaX/glaBNPgOrW5Tdt8A/RKQy8KGq/iQiTYAzgKlBeZMDsKSTk3dFZDvwM1aG+iRgqaouDO5/G7gdeAVb66KfiPwXiLmkuaquFZElQZ2dn4LnmBQ8bn7iPAgrVxG5Qlk7EemK/b8+GlugZ3a2320Y7J8UPE8p7Lw5lytPFC5Z9ADWAKdhV8J/WZRIVQeLyHdAc2CMiHTByiq/rar3x/AcHSMLCIpIjuubBLWF6mNF5toDdwAX5uO1vAe0A34ERqiqin1qxxwntorbU0Af4AoRqQbcDZypqhtEZCBW+C47Af6nqh3yEa8r5rzpySWLQ4BVwfoBnbBv03sRkeOBJUFzy2isCeZLoK2IHBEcc7jEvqb4j0BVEakebHcCJgRt+oeo6idYR3FOI482Y2XPc/Ih0BpbI+G9YF++4lTVXVgTUsOg2epgYCuwSUSOBC7NJZbJwDmZr0lEDhSRnK7OnPuTJwqXLF4FrhORyViz09YcjrkKmCMiM4GTsSUf52EfqJ+LyGzgf1izTJ5UNR2rrjlMRH4A9gCvYx+6HwePNwG72sluIPB6Zmd2tsfdAMwDjlPVKcG+fMcZ9H08B9ytqrOw9bHnAgOw5qxMfYFPRWScqq7FRmQNCZ5nMnaunMuVV491zjkXlV9ROOeci8oThXPOuag8UTjnnIvKE4VzzrmoPFE455yLyhOFc865qDxROOeci+r/AU1YtQgn8c51AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rocCurvePlot(rf_clf.predict_proba(X_test_scaled), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to create viz of one tree\n",
    "final_model_forviz=rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to export the tree \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Write the decision tree as a dot file\n",
    "visual_tree =final_model_forviz.estimators_[12]\n",
    "export_graphviz(visual_tree, out_file = 'C:/Users/Zack/Desktop/best_tree.dot', feature_names = df_imputed.columns.values, \n",
    "                precision = 2, filled = True, rounded = True, max_depth = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pydot for converting to an image file\n",
    "#pip3 install pydot\n",
    "import pydot\n",
    "\n",
    "# Import the dot file to a graph and then convert to a png\n",
    "(graph, ) = pydot.graph_from_dot_file('C:/Users/Zack/Desktop/best_tree.dot')\n",
    "graph.write_jpg('C:/Users/Zack/Desktop/best_tree.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost df_imputed_min dataset model vs. baseline model with all variables model\n",
    "\n",
    "### XGBoost baseline  model for df_imputed_min dataset\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "#XGBOOST parameters 1\n",
    "MAX_ROUNDS = 1000\n",
    "EARLY_STOP = 50\n",
    "OPT_ROUNDS = 1000\n",
    "VERBOSE_EVAL = 50\n",
    "RANDOM_STATE = 2000\n",
    "\n",
    "#XGBOOST transform data into DMatrix format for modeling\n",
    "dtrain = xgb.DMatrix(X_train_scaled, y_train)\n",
    "dvalid = xgb.DMatrix(X_test_scaled, y_test)\n",
    "type(dtrain)\n",
    "\n",
    "\n",
    "# XGBoost Parameters 2\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "#params['objective'] = 'multi:softmax'\n",
    "#params['objective'] = 'reg:linear'\n",
    "params['eta'] = 0.039\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 2\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.9\n",
    "params['eval_metric'] = 'auc'\n",
    "params['random_state'] = RANDOM_STATE\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.630167\tvalid-auc:0.626652\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.712641\tvalid-auc:0.711675\n",
      "[100]\ttrain-auc:0.719279\tvalid-auc:0.71933\n",
      "[150]\ttrain-auc:0.725965\tvalid-auc:0.727298\n",
      "[200]\ttrain-auc:0.729865\tvalid-auc:0.731484\n",
      "[250]\ttrain-auc:0.732551\tvalid-auc:0.734486\n",
      "[300]\ttrain-auc:0.734347\tvalid-auc:0.736519\n",
      "[350]\ttrain-auc:0.735593\tvalid-auc:0.737706\n",
      "[400]\ttrain-auc:0.736622\tvalid-auc:0.738797\n",
      "[450]\ttrain-auc:0.737973\tvalid-auc:0.739935\n",
      "[500]\ttrain-auc:0.738855\tvalid-auc:0.7408\n",
      "[550]\ttrain-auc:0.739727\tvalid-auc:0.741469\n",
      "[600]\ttrain-auc:0.740305\tvalid-auc:0.742042\n",
      "[650]\ttrain-auc:0.740912\tvalid-auc:0.742415\n",
      "[700]\ttrain-auc:0.741497\tvalid-auc:0.742847\n",
      "[750]\ttrain-auc:0.742118\tvalid-auc:0.743257\n",
      "[800]\ttrain-auc:0.742659\tvalid-auc:0.743525\n",
      "[850]\ttrain-auc:0.743049\tvalid-auc:0.743724\n",
      "[900]\ttrain-auc:0.743634\tvalid-auc:0.743976\n",
      "[950]\ttrain-auc:0.744101\tvalid-auc:0.744181\n",
      "[999]\ttrain-auc:0.744676\tvalid-auc:0.744422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_clf = xgb.train(params,\n",
    "                   dtrain,\n",
    "                   MAX_ROUNDS,\n",
    "                   watchlist,\n",
    "                   early_stopping_rounds = EARLY_STOP,\n",
    "                   maximize = True,\n",
    "                   verbose_eval = VERBOSE_EVAL)\n",
    "\n",
    "\n",
    "#all variables model\n",
    "#Wall time: 3min 48s\n",
    "#[999]\ttrain-auc:0.756217\tvalid-auc:0.748447\n",
    "\n",
    "#df_imputed_min dataset model (12 varibales) without 'medication_count'\n",
    "#train within one min, similar auc\n",
    "#[999]\ttrain-auc:0.74347\tvalid-auc:0.743672\n",
    "\n",
    "\n",
    "#df_imputed_min dataset model with 'medication_count'\n",
    "# train for one min\n",
    "#[999]\ttrain-auc:0.744676\tvalid-auc:0.744422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "#at least include the parameters already included in the baseline model for chance to find one better than base model.\n",
    "params = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 2],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.9],\n",
    "        'max_depth': [2, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed:  1.7min remaining:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed:  1.8min remaining:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed:  2.0min remaining:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed:  2.6min remaining:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed:  2.6min remaining:   45.3s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:  2.8min finished\n",
      "\n",
      " Time taken: 0 hours 4 minutes and 18.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Thanks for Zack's suggestion\n",
    "# under the condition of same list of parameters to be tuned:\n",
    "# all variables model runtime 24-30 mins\n",
    "# df_imputed_min dataset model 4 mins\n",
    "## grid search in a parallized fashion\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "folds = 3\n",
    "param_comb = 3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train_scaled,y_train), verbose=50, random_state=2000)\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
      "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=0.6)\n",
      "\n",
      " Best normalized gini score for 3-fold search with 3 parameter combinations:\n",
      "0.4868555900780789\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Best hyperparameters\n",
    "\n",
    "Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
    "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.6)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 3 parameter combinations:\n",
    "0.4868555900780789\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 1 minutes and 22.29 seconds.\n"
     ]
    }
   ],
   "source": [
    "#traing time comparsion\n",
    "#df_imputed_min dataset model vs. baseline model with all variables model\n",
    "#run for \n",
    "#evaulate the performance of the model best parameters\n",
    "# timer the training time\n",
    "start_time = timer(None)\n",
    "\n",
    "xgb_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
    "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.6)\n",
    "\n",
    "xgb_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "timer(start_time)\n",
    "\n",
    "#training time\n",
    "#all variables model Time taken: 0 hours 8 minutes and 24.05 seconds.\n",
    "#df_imputed_min dataset model Time taken: 0 hours 1 minutes and 22.29 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 0 minutes and 0.63 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N1110\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# timer the testing time\n",
    "start_time = timer(None)\n",
    "preds = xgb_best.predict(X_test_scaled)\n",
    "timer(start_time)\n",
    "\n",
    "#testing time\n",
    "# all variables model  Time taken: 0 hours 0 minutes and 0.91 seconds.\n",
    "#df_imputed_min dataset model   Time taken: 0 hours 0 minutes and 0.63 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB - roc_auc_score:  0.6696882681547426\n"
     ]
    }
   ],
   "source": [
    "print('XGB - roc_auc_score: ', roc_auc_score(y_test, preds)) \n",
    "#all variables model  XGB - roc_auc_score:  0.677932172132421\n",
    "#df_imputed_min dataset model  XGB - roc_auc_score:  0.6696882681547426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -9.95%.\n"
     ]
    }
   ],
   "source": [
    "#improvement after parameter tuning\n",
    "\n",
    "# The reason I want to keep both baseline model and refined model is to show the effect of Hyperparameter Tuning. \n",
    "# To see increase the AUC by what percentage.\n",
    "\n",
    "XGBrandom_accuracy = 0.6696882681547426\n",
    "XGBbase_accuracy =0.743672\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (XGBrandom_accuracy - XGBbase_accuracy) / XGBbase_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### since the runtime reduced sigificantly for df_imputed_min dataset model (1/8), able to try larger set of parameters\n",
    "\n",
    "#### used\n",
    "params = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 2],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.9],\n",
    "        'max_depth': [2, 5]\n",
    "        }\n",
    "\n",
    "param_comb = 3\n",
    "\n",
    "32 combinations\n",
    "\n",
    "#### Now want to try A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [2, 3, 4, 5]\n",
    "        }\n",
    "        \n",
    "param_comb = 5\n",
    "\n",
    "3*4*3*4*4= 576 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*4*3*4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [2, 3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:  5.6min remaining:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:  5.7min remaining:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:  5.7min remaining:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:  6.1min remaining:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:  6.8min remaining:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:  7.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:  7.0min finished\n",
      "\n",
      " Time taken: 0 hours 8 minutes and 18.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Grid search in a parallized fashion\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train_scaled,y_train), verbose=50, random_state=2000)\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#for df_imputed_min dataset model without 'medication_count' Time taken: 0 hours 8 minutes and 0.77 seconds.\n",
    "# for df_imputed_min dataset model without 'medication_count'   Time taken: 0 hours 8 minutes and 18.21 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
      "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
      "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1.0)\n",
      "\n",
      " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
      "0.48660500355915715\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from narrow list\n",
    "#### Results - Best hyperparameters for all variables model\n",
    "\n",
    "Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=2, learning_rate=0.02, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
    "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.6)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 3 parameter combinations:\n",
    "0.4868555900780789\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}\n",
    "\n",
    "#### Results from larger list for df_imputed_min dataset model without 'medication_count'\n",
    " Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
    "0.48276429835940937\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}\n",
    "\n",
    "\n",
    "#### Results from larger list for df_imputed_min dataset model without 'medication_count'\n",
    "#### same results of parameters as df_imputed_min dataset model without 'medication_count'\n",
    " Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
    "0.48660500355915715\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 1 minutes and 27.16 seconds.\n"
     ]
    }
   ],
   "source": [
    "#evaulate the performance of the model best parameters\n",
    "# timer the training time\n",
    "start_time = timer(None)\n",
    "\n",
    "xgb_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    "xgb_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 0 minutes and 0.57 seconds.\n"
     ]
    }
   ],
   "source": [
    "# timer the testing time\n",
    "start_time = timer(None)\n",
    "preds = xgb_best.predict(X_test_scaled)\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB - roc_auc_score:  0.6688937079820751\n"
     ]
    }
   ],
   "source": [
    "print('XGB - roc_auc_score: ', roc_auc_score(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -10.06%.\n"
     ]
    }
   ],
   "source": [
    "#improvement after parameter tuning\n",
    "\n",
    "XGBrandom_accuracy = 0.6688937079820751\n",
    "# 0.6688937079820751 for df_imputed_min dataset model with 'medication_count' \n",
    "# 0.6691181476110993  for df_imputed_min dataset model without 'medication_count' \n",
    "# 0.6696882681547426 for all variables model\n",
    "\n",
    "\n",
    "# show the impact of FE (feature engineering)\n",
    "# 'medication_count' varibale does help with increase the auc \n",
    "\n",
    "#also, insulin seem to be a important varibale according to important plot in another notebook. \n",
    "# it makes so much sense and align with our domain knowledge.\n",
    "\n",
    "XGBbase_accuracy =0.743672\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (XGBrandom_accuracy - XGBbase_accuracy) / XGBbase_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for 10 mins\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "#%%time\n",
    "#try run with all medications\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM AUC: 0.6672284951485267\n"
     ]
    }
   ],
   "source": [
    "#get SVM AUC\n",
    "roc = roc_auc_score(y_test,y_hat)\n",
    "print('SVM AUC:', roc )\n",
    "\n",
    "#SVM AUC for all variables model:  SVM AUC: 0.6658213006434637\n",
    "#SVM AUC for df_imputed_min model: SVM AUC: 0.6672284951485267  higherthan all variables model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
